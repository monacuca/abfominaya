---
title: "MoonBuddy"
excerpt: "In Adjunct Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology (UIST '22 Adjunct). Association for Computing Machinery, New York, NY, USA, Article 4, 1â€“4. https://doi.org/10.1145/3526114.3558690 "
coverImage: "/assets/blog/projects/moonbuddy/01.png"
date: "20220501"
author:
  name: Angelica Bonilla (A.B.) Fominaya
  picture: "/assets/blog/authors/abf.png"
ogImage:
  url: "/assets/blog/projects/moonbuddy/01.png"
carrouselImages:
  - key: "1"
    url: "/assets/blog/projects/moonbuddy/01.png"
    caption: "1"
  - key: "2"
    url: "/assets/blog/projects/moonbuddy/02.jpg"
    caption: "2"
  - key: "3"
    url: "/assets/blog/projects/moonbuddy/03.jpg"
    caption: "3"
  - key: "4"
    url: "/assets/blog/projects/moonbuddy/04.jpg"
    caption: "4"
  - key: "5"
    url: "/assets/blog/projects/moonbuddy/05.jpg"
    caption: "5"
  - key: "6"
    url: "/assets/blog/projects/moonbuddy/06.jpg"
    caption: "6"
  - key: "7"
    url: "/assets/blog/projects/moonbuddy/07.jpg"
    caption: "7"
  - key: "8"
    url: "/assets/blog/projects/moonbuddy/08.jpg"
    caption: "8"
  - key: "9"
    url: "/assets/blog/projects/moonbuddy/09.jpg"
    caption: "9"
tags: [
  "research",
  "vr/ar",
  "technology",
  "poster",
  "space",
  "uist"
]
mediaType: "research"
---
# MoonBuddy: A Voice-based Augmented Reality User Interface That Supports Astronauts During Extravehicular Activities. 
Access the paper [here (click)](https://doi.org/10.1145/3526114.3558690).
## Authors: 
- **Bonilla Fominaya, Angelica M.**
- Chew, Rong Kang (Ron)
- Komar, Matthew L.
- Lo, Jeremia
- Slabakis, Alexandra
- Sun, Ningjing (Anita)
- Zhang, Yunyi (Joyce)
- Lindlbauer, David
## Abstract:
As NASA pursues Artemis missions to the moon and beyond, it is 
essential to equip astronauts with the appropriate human-autonomy 
enabling technology necessary for the elevated demands of lunar 
surface exploration and extreme terrestrial access. We present 
MoonBuddy, an application built for the Microsoft HoloLens 2 that 
utilizes Augmented Reality (AR) and voice-based interaction to assist 
astronauts in communication, navigation, and documentation on 
future lunar extravehicular activities (EVAs), with the goal of reducing 
cognitive load and increasing effective task completion.
We performed a preliminary evaluation at the Johnson Space Center,
Houston, TX, USA, in an area that simulates the lunar surface and
its lighting conditions. During testing, participants used MoonBuddy to 
navigate to three different geological sampling sites, collect rock 
samples, and perform a search and rescue mission to find a distressed 
crew member. Overall, participants appreciated the simple voice 
commands, the guided nature of MoonBuddy, and the surface
edge detection feature that helped them avoid hazards during navigation.

## Personal note:
I led and organized team of 8 designers, artists and programmers to develop an AR application for EVA
assistance, which we had the opportunity to test NASA Johnson Space Center. We wrote a poster and paper
detailing implementation details, which was accepted and is to be presented in UIST'22. To create this project
we received grants from the Pennsylvania Space Grant Consortium and Carnegie Mellon's Human-Computer Interaction Institute.